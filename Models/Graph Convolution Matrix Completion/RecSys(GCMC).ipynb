{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Recommender Systems with GNNs} $\n",
    "\n",
    "GNN을 추천 시스템, 사기 탐지 등과 같은 다양한 분야에 적용하고자 하는 연구가 많이 진행되고 있습니다.\n",
    "\n",
    "본 tutorial에서는 추천 시스템을 위한 GNN을 다룹니다. \n",
    "\n",
    "추천 시스템은 사용자가 선호할만한 제품을 추천하는 시스템입니다. 사용자에게 제품을 추천할 때 활용하는 데이터는 평점 등과 같은 Explicit feedback을 활용하는 경우와 구매 기록, 클릭 등과 같은 implicit feedback을 활용하는 경우로 나눌 수 있습니다. explicit feedback의 경우 모델이 예측한 평점과 실제 사용자가 제품에 부여한 평점 간의 차이를 최소화하는 방향으로 모델을 학습합니다.\n",
    "$$\n",
    "\\min_{u, v} \\sum_{i, j \\in \\mathcal{D}} (\\hat{r}_{i,j} - r_{i, j})^2\n",
    "$$\n",
    "추천 시스템에서 가장 대표적인 모델 중 하나인 행렬 분해(Matrix Factorization) 모델의 경우 user vector $u$와 item vector $v$ 간의 내적을 통해 평점을 예측합니다. \n",
    "\n",
    "$\\hat{r}_{i, j} = u^T_i v_j + \\beta_i + \\gamma_j $, 이때 $\\beta_i$와 $\\gamma_j$는 각각 사용자와 제품에 대한 bias를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie lens 데이터를 사용하였습니다. \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "train_data = pd.read_csv('data/ua.base', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "test_data = pd.read_csv('data/ua.test', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "user_data = pd.read_csv('data/u.user', sep='|', header=None, encoding='latin1')\n",
    "item_data = pd.read_csv('data/u.item', sep='|', header=None, encoding='latin1')\n",
    "\n",
    "'''\n",
    "실제 모델을 학습한 후 추천 성능을 측정하기 위해서는 train dataset에 존재하는 사용자 및 제품에 대해서만 사용하여야 합니다. \n",
    "따라서, test_data에 train_data에서는 존재하지 않는 사용자와 제품이 존재하는 경우 제거하는 작업을 수행합니다.\n",
    "'''\n",
    "\n",
    "test_data = test_data.loc[(test_data.loc[:,'user_id'].isin(train_data.loc[:,'user_id'])) & \n",
    "                          (test_data.loc[:,'item_id'].isin(train_data.loc[:,'item_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2           3      4\n",
       "0  1  24  M  technician  85711\n",
       "1  2  53  F       other  94043\n",
       "2  3  23  M      writer  32067\n",
       "3  4  24  M  technician  43537\n",
       "4  5  33  F       other  15213"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                  1            2   3   \\\n",
       "0   1   Toy Story (1995)  01-Jan-1995 NaN   \n",
       "1   2   GoldenEye (1995)  01-Jan-1995 NaN   \n",
       "2   3  Four Rooms (1995)  01-Jan-1995 NaN   \n",
       "3   4  Get Shorty (1995)  01-Jan-1995 NaN   \n",
       "4   5     Copycat (1995)  01-Jan-1995 NaN   \n",
       "\n",
       "                                                  4   5   6   7   8   9   ...  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...   0   0   0   1   1  ...   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...   0   1   1   0   0  ...   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...   0   0   0   0   0  ...   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...   0   1   0   0   0  ...   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)   0   0   0   0   0  ...   \n",
       "\n",
       "   14  15  16  17  18  19  20  21  22  23  \n",
       "0   0   0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   1   0   0  \n",
       "2   0   0   0   0   0   0   0   1   0   0  \n",
       "3   0   0   0   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0   1   0   0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\text{Heterogeneous Graphs in DGL} $\n",
    "\n",
    "Heterogeneous Graph는 그래프 내에 노드의 class가 1개가 아닌 그래프를 칭합니다. \n",
    "\n",
    "추천 시스템의 경우 사용자 노드와 제품 노드로 되어 있는 Bipartite Graph이기에 Heterogeneous Graph 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EonKim\\anaconda3\\envs\\dgl\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2747: FutureWarning: The `inplace` parameter in pandas.Categorical.set_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import dgl \n",
    "import torch \n",
    "\n",
    "'''\n",
    "사용자와 제품에 대한 label을 양의 정수 형태로 변환합니다. \n",
    "만약 user_id와 label_id가 사용자의 이름 혹은 제품명으로 되어 있는 경우 laebel_encoding을 통해 변환할 수 있습니다.\n",
    "'''\n",
    "\n",
    "train_data = train_data.astype({'user_id': 'category', 'item_id': 'category'})\n",
    "test_data = test_data.astype({'user_id': 'category', 'item_id': 'category'})\n",
    "\n",
    "# train data과 test data의 사용자와 제품에 대한 label이 동일해야 합니다. \n",
    "test_data['user_id'].cat.set_categories(train_data['user_id'].cat.categories, inplace=True)\n",
    "test_data['item_id'].cat.set_categories(train_data['item_id'].cat.categories, inplace=True)\n",
    "\n",
    "\n",
    "train_user_ids = torch.LongTensor(train_data['user_id'].cat.codes.values)\n",
    "train_item_ids = torch.LongTensor(train_data['item_id'].cat.codes.values)\n",
    "train_ratings = torch.LongTensor(train_data['rating'].values)\n",
    "\n",
    "test_user_ids = torch.LongTensor(test_data['user_id'].cat.codes.values)\n",
    "test_item_ids = torch.LongTensor(test_data['item_id'].cat.codes.values)\n",
    "test_ratings = torch.LongTensor(test_data['rating'].values)\n",
    "\n",
    "\n",
    "# Build Graph \n",
    "# 양방향에 대해서 입력을 해주어야 하기 때문에 user -> item, item -> user 에 대해서 모두 작성해 주어야 합니다. \n",
    "# train_user_ids와 train_item_ids는 1D tensor, 1D tensor pair 형태로 입력하셔야 됩니다.\n",
    "graph = dgl.heterograph({\n",
    "    ('user', 'watched', 'item'): (train_user_ids, train_item_ids), \n",
    "    ('item', 'watched-by', 'user'): (train_item_ids, train_user_ids)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 1680, 'user': 943},\n",
       "      num_edges={('item', 'watched-by', 'user'): 90570, ('user', 'watched', 'item'): 90570},\n",
       "      metagraph=[('item', 'user', 'watched-by'), ('user', 'item', 'watched')])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* movie genres: one-hot encoding으로 구성되어 있습니다. \n",
    "* User age: 사용자의 나이를 10년 단위로 묶어서 categorical variable로 변환합니다.\n",
    "* User gender: categorical variable\n",
    "* User occupation(직업): a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ids\n",
    "user_data[0] = user_data[0].astype('category')\n",
    "user_data[0] = user_data[0].cat.set_categories(train_data['user_id'].cat.categories)\n",
    "user_data = user_data.dropna(subset=[0]) # train data에 없는 사용자는 제거합니다. \n",
    "user_data[0] = user_data[0].cat.codes\n",
    "user_data = user_data.sort_values(0)\n",
    "\n",
    "item_data[0] = item_data[0].astype('category')\n",
    "item_data[0] = item_data[0].cat.set_categories(train_data['item_id'].cat.categories)\n",
    "item_data = item_data.dropna(subset=[0]) # train data에 없는 제품은 제거합니다. \n",
    "item_data[0] = item_data[0].cat.codes\n",
    "item_data = item_data.sort_values(0)\n",
    "\n",
    "# gender\n",
    "user_data[2] = user_data[2].astype('category')\n",
    "\n",
    "# occupation\n",
    "user_data[3] = user_data[3].astype('category')\n",
    "\n",
    "# ??\n",
    "user_data[4] = user_data[4].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "user_age = user_data[1].values // 10\n",
    "num_user_age_bins = user_age.max() + 1     # count the number of user age bins\n",
    "user_gender = user_data[2].cat.codes.values\n",
    "num_user_genders = len(user_data[2].cat.categories)\n",
    "user_occupation = user_data[3].cat.codes.values\n",
    "num_user_occupations = len(user_data[3].cat.categories)\n",
    "\n",
    "item_genres = item_data[range(5, 24)].values # one-hot encoding \n",
    "num_item_genres = item_genres.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes['user'].data['age'] = torch.LongTensor(user_age)\n",
    "graph.nodes['user'].data['gender'] = torch.LongTensor(user_gender)\n",
    "graph.nodes['user'].data['occupation'] = torch.LongTensor(user_occupation)\n",
    "\n",
    "graph.nodes['item'].data['genres'] = torch.FloatTensor(item_genres)\n",
    "\n",
    "# weight edges\n",
    "graph.edges['watched'].data['rating'] = torch.LongTensor(train_ratings)\n",
    "graph.edges['watched-by'].data['rating'] = torch.LongTensor(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# TensorDataset의 경우 Dataset과는 달리 Tensor만 입력으로 받을 수 있습니다.\n",
    "train_dataset = TensorDataset(train_user_ids, train_item_ids, train_ratings)\n",
    "test_dataset = TensorDataset(test_user_ids, test_item_ids, test_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Define Minibatch \\& Neighbor Sampler} $\n",
    "\n",
    "multi-layer GNN을 사용하기 위해서는 먼저 Minibatch sampler를 정의해야 합니다. \n",
    "\n",
    "추천 시스템에서는 사용자와 제품 간의 종속성(Dependency)이 존재하기 때문에 이를 고려하여 계산하기 위함입니다. \n",
    "\n",
    "\n",
    "**neighbor sampler**\n",
    "1. batch size 만큼의 pair_graph를 추출합니다. (heterograph를 생성)\n",
    "2. compact_graph로 변환합니다. parir_graph로 sampling된 node 중 아무 노드와 연결되어 있지 않는 노드를 제거하는 작업 입니다. \n",
    "3. block을 생성합니다.\n",
    "\n",
    "**construct_blocks**\n",
    "1. graph의 edge(link) 정보를 불러옵니다. \n",
    "2. 모델 학습을 위해 edge의 정보를 제거합니다. (모델이 사용자와 제품이 연결되어 있는 정보를 알고 있으면 학습하는 것에 의미가 없기 때문.)\n",
    "3. edge 정보를 제거한 graph를 block에 저장합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchSampler(object):\n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def sample(self, batch):\n",
    "        users, items, ratings = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        ratings = torch.stack(ratings)\n",
    "        \n",
    "        # Create a pair graph (Step 1)\n",
    "        pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "        # Compact the graph (Step 2)\n",
    "        # compact_graph는 isolated node를 찾아서 제거하는 역할을 합니다. 구체적으로 node의 degree, out-degree가 0인 node를 제거합니다.\n",
    "        pair_graph = dgl.compact_graphs(pair_graph)\n",
    "        \n",
    "        # Assign ratings to the graph\n",
    "        pair_graph.edata['rating'] = ratings\n",
    "        \n",
    "        # Construct blocks (Step 3)\n",
    "        # 분산처리를 하기 위한 전처리 과정입니다.\n",
    "        # NID/EID는 subgraph의 node와 edge들이 reshuffle 후의 전체 graph의 새로운 node/edge ID를 저장합니다. \n",
    "        # 학습이 실행되는 동안, 새로운 node/edge ID만을 사용하는 것입니다. (node와 edge를 구별하기 위함입니다.)\n",
    "        seeds = {'user': pair_graph.nodes['user'].data[dgl.NID],\n",
    "                 'item': pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        blocks = self.construct_blocks(seeds, (users, items))\n",
    "        \n",
    "        for feature_name in self.graph.nodes['user'].data.keys():\n",
    "            blocks[0].srcnodes['user'].data[feature_name] = \\\n",
    "                self.graph.nodes['user'].data[feature_name][blocks[0].srcnodes['user'].data[dgl.NID]]\n",
    "                \n",
    "        for feature_name in self.graph.nodes['item'].data.keys():\n",
    "            blocks[0].srcnodes['item'].data[feature_name] = \\\n",
    "                self.graph.nodes['item'].data[feature_name][blocks[0].srcnodes['item'].data[dgl.NID]]\n",
    "\n",
    "        return pair_graph, blocks\n",
    "    \n",
    "    def construct_blocks(self, seeds, user_item_pairs_to_remove):\n",
    "        blocks = []\n",
    "        users, items = user_item_pairs_to_remove\n",
    "        for i in range(self.num_layers):\n",
    "            sampled_graph = dgl.in_subgraph(self.graph, seeds) # seed로 지정된 subgraph를 반환합니다. \n",
    "            \n",
    "            sampled_eids = sampled_graph.edges['watched'].data[dgl.EID]\n",
    "            sampled_eids_rev = sampled_graph.edges['watched-by'].data[dgl.EID]\n",
    "            \n",
    "            # rating을 예측하는 것은 edge를 예측하는 것과 같으며, \n",
    "            # sub graph의 edge를 예측할 때 모델이 연결되어 있다는 정보를 알지 못하도록 remove 합니다.\n",
    "            # 모델이 연결되어 있다는 정보를 알고 있다면, 예측의 의미가 없기 때문입니다.\n",
    "            _, _, edges_to_remove = sampled_graph.edge_ids(users, items, etype='watched', return_uv=True)\n",
    "            _, _, edges_to_remove_rev = sampled_graph.edge_ids(items, users, etype='watched-by', return_uv=True)\n",
    "            \n",
    "            sampled_with_edges_removed = sampled_graph \n",
    "            \n",
    "            if len(edges_to_remove) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove, 'watched'\n",
    "                )\n",
    "                sampled_eids = sampled_eids[sampled_with_edges_removed.edges['watched'].data[dgl.EID]]\n",
    "            \n",
    "            if len(edges_to_remove_rev) > 0:\n",
    "                sampled_with_edges_removed = dgl.remove_edges(\n",
    "                    sampled_with_edges_removed, edges_to_remove_rev, 'watched-by'\n",
    "                )\n",
    "                sampled_eids_rev = sampled_eids_rev[sampled_with_edges_removed.edges['watched-by'].data[dgl.EID]]\n",
    "                \n",
    "            # Create a block from the sampled graph.\n",
    "            block = dgl.to_block(sampled_with_edges_removed, seeds)\n",
    "            blocks.insert(0, block)\n",
    "            seeds = {'user':block.srcnodes['user'].data[dgl.NID], \n",
    "                     'item':block.srcnodes['item'].data[dgl.NID]}\n",
    "            \n",
    "            # copy the ratings to the edges of sampled block\n",
    "            block.edges['watched'].data['rating'] = \\\n",
    "                self.graph.edges['watched'].data['rating'][sampled_eids]\n",
    "            \n",
    "            block.edges['watched-by'].data['rating'] = \\\n",
    "                self.graph.edges['watched-by'].data['rating'][sampled_eids_rev]\n",
    "        \n",
    "        return blocks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Define Model}$\n",
    "\n",
    "본 tutorial에서 사용하는 $\\text{Graph Convolutional Matrix Completion} $(GCMC)은 매우 간단한 버전 입니다. \n",
    "\n",
    "GCMC는 각 노드의 representation을 계산하여 이웃에게 message를 보냅니다. \n",
    "\n",
    "각각의 노드는 전달받은 message를 모으고, 평균을 취해 node representation으로 사용합니다. \n",
    "\n",
    "$ \\ $\n",
    "\n",
    "$l^{\\text{th}}-layer$의 representation을 update하는 경우:\n",
    "\n",
    "1. node $i$와 interaction이 존재하는 모든 이웃을 찾습니다.\n",
    "\n",
    "2. 그 후, user $i$가 item $j$에 남긴 rating $r_{ij}$를 확인하고 linear projection을 통해 message를 전달합니다. \n",
    "$$\n",
    "m^l_{j \\rightarrow i} \\leftarrow W^l_{r_{ij}}v^{l-1}_j\n",
    "$$\n",
    "\n",
    "3. node $i$와 전달받은 message를 합계하여 $u^l_i$를 update 합니다. \n",
    "$$\n",
    "u^l_i \\leftarrow \\text{ReLU} ( W^l [\\sum(m^l_{j \\rightarrow i}); u^{l-1}_i])\n",
    "$$\n",
    "\n",
    "$ \\ $\n",
    "\n",
    "실제 모델을 학습할 때 edge 즉, rating을 제거했습니다. 따라서, 모델은 $W^l_{r_ij}, W^l$을 학습하며 최적화 합니다. \n",
    "\n",
    "![image_1](asset/figure_1.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import dgl.function as fn \n",
    "import dgl.nn as dglnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCConv(nn.Module):\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        # rating은 1부터 시작하기 때문에 + 1을 합니다. \n",
    "        self.W_r = nn.Parameter(torch.randn(num_ratings+1, hidden_dims, hidden_dims))\n",
    "        self.W = nn.Linear(hidden_dims*2, hidden_dims)\n",
    "        \n",
    "    def compute_message(self, W, edges):\n",
    "        W_r = W[edges.data['rating']]\n",
    "        h = edges.src['h']\n",
    "        m = (W_r @ h.unsqueeze(-1)).squeeze(2)\n",
    "        return m \n",
    "    \n",
    "    def forward(self, graph, node_features):\n",
    "        with graph.local_scope():\n",
    "            src_features, dst_features = node_features\n",
    "            graph.srcdata['h'] = src_features \n",
    "            graph.dstdata['h'] = dst_features \n",
    "            \n",
    "            # Compute messages \n",
    "            graph.apply_edges(lambda edges: {'m': self.compute_message(self.W_r, edges)})\n",
    "            \n",
    "            # Aggregate messages \n",
    "            graph.update_all(fn.copy_e('m', ','), fn.mean('m', 'h_neigh'))\n",
    "            \n",
    "            # Update the representations of output users and items \n",
    "            result = F.relu(self.W(torch.cat([graph.dstdata['h'], graph.dstdata['h_neigh']], 1)))\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCLayer(nn.Module):\n",
    "    def __init__(self, hidden_dims, num_ratings):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.heteroconv = dglnn.HeteroGraphConv(\n",
    "            {'watched': GCMCConv(hidden_dims, num_ratings), 'watched-by': GCMCConv(hidden_dims, num_ratings)}, \n",
    "            aggregate='sum'\n",
    "        )\n",
    "    \n",
    "    def forward(self, block, input_user_features, input_item_features):\n",
    "        with block.local_scope():\n",
    "            h_user = input_user_features \n",
    "            h_item = input_item_features \n",
    "            \n",
    "            src_features = {'user':h_user, 'item':h_item}\n",
    "            \n",
    "            dst_features = {'user':h_user[:block.number_of_dst_nodes('user')], 'item': h_item[:block.number_of_dst_nodes('item')]}\n",
    "            \n",
    "            result = self.heteroconv(block, (src_features, dst_features))\n",
    "            return result['user'], result['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCMCRating(nn.Module):\n",
    "    def __init__(self, num_users, num_items, hidden_dims, num_ratings, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, hidden_dims)\n",
    "        self.item_embeddings = nn.Embedding(num_items, hidden_dims)\n",
    "        \n",
    "        self.U_age = nn.Embedding(num_user_age_bins, hidden_dims)\n",
    "        self.U_gender = nn.Embedding(num_user_genders, hidden_dims)\n",
    "        self.U_occupation = nn.Embedding(num_user_occupations, hidden_dims)\n",
    "        self.U_genres = nn.Linear(num_item_genres, hidden_dims)\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            GCMCLayer(hidden_dims, num_ratings) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.W = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.V = nn.Linear(hidden_dims, hidden_dims)\n",
    "        \n",
    "    def forward(self, blocks):\n",
    "        user_embeddings = self.user_embeddings(blocks[0].srcnodes['user'].data[dgl.NID])\n",
    "        item_embeddings = self.item_embeddings(blocks[0].srcnodes['item'].data[dgl.NID])\n",
    "        \n",
    "        # user_embedding에 사용할 user_feature를 추가하는 작업을 수행합니다. \n",
    "        user_embeddings += self.U_age(blocks[0].srcnodes['user'].data['age'])\n",
    "        user_embeddings += self.U_gender(blocks[0].srcnodes['user'].data['gender'])\n",
    "        user_embeddings += self.U_occupation(blocks[0].srcnodes['user'].data['occupation'])\n",
    "        item_embeddings += self.U_genres(blocks[0].srcnodes['item'].data['genres'])\n",
    "        \n",
    "        for block, layer in zip(blocks, self.layers):\n",
    "            user_embeddings, item_embeddings = layer(block, user_embeddings, item_embeddings)\n",
    "            \n",
    "        user_embeddings = self.W(user_embeddings)\n",
    "        item_embeddings = self.V(item_embeddings)\n",
    "        \n",
    "        return user_embeddings, item_embeddings \n",
    "    \n",
    "    def compute_score(self, pair_graph, user_embeddings, item_embeddings):\n",
    "        with pair_graph.local_scope():\n",
    "            pair_graph.nodes['user'].data['h'] = user_embeddings \n",
    "            pair_graph.nodes['item'].data['h'] = item_embeddings \n",
    "            pair_graph.apply_edges(fn.u_dot_v('h', 'h', 'r'))\n",
    "            \n",
    "            return pair_graph.edata['r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Define Evaluation Metric} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, label):\n",
    "    return ((pred-label)^2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Train Loop} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "\n",
    "NUM_LAYERS = 1 \n",
    "BATCH_SIZE = 500 \n",
    "NUM_EPOCHS = 50 \n",
    "HIDDEN_DIMS = 8\n",
    "\n",
    "sampler = MinibatchSampler(graph, NUM_LAYERS)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=sampler.sample, shuffle=False)\n",
    "\n",
    "model = GCMCRating(graph.number_of_nodes('user'), graph.number_of_nodes('item'), HIDDEN_DIMS, 5, NUM_LAYERS)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for _ in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(train_dataloader) as t:\n",
    "        for pair_graph, blocks in t: \n",
    "            user_emb, item_emb = model(blocks)\n",
    "            prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "            loss = ((prediction - pair_graph.edata['rating']) ** 2).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': '%.4f' % loss.item()}, refresh=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with tqdm.tqdm(test_dataloader) as t:\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            ratings = []\n",
    "            for pair_graph, blocks in t:\n",
    "                user_emb, item_emb = model(blocks)\n",
    "                prediction = model.compute_score(pair_graph, user_emb, item_emb)\n",
    "                predictions.append(prediction)\n",
    "                ratings.append(pair_graph.edata['rating'])\n",
    "            \n",
    "            predictions = torch.cat(predictions, dim=0)\n",
    "            ratings = torch.cat(ratings, dim=0)\n",
    "        \n",
    "        print('RMSE', rmse(predictions, ratings).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Option Implicit Feedback} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictionMinibatchSampler(MinibatchSampler):\n",
    "    def __init__(self, graph, num_layers):\n",
    "        self.graph = graph\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def sample(self, batch):\n",
    "        # Convert the list of user-item-rating triplets into a pairs of users and items\n",
    "        users, items, _ = zip(*batch)\n",
    "        users = torch.stack(users)\n",
    "        items = torch.stack(items)\n",
    "        # negative sampling\n",
    "        neg_items = torch.randint(0, self.graph.number_of_nodes('item'), (len(users),))\n",
    "        \n",
    "        # Create a pair graph for positive examples and negative examples (Step 1)\n",
    "        pos_pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        neg_pair_graph = dgl.heterograph(\n",
    "            {('user', 'watched', 'item'): (users, neg_items)},\n",
    "            num_nodes_dict={'user': self.graph.number_of_nodes('user'), 'item': self.graph.number_of_nodes('item')})\n",
    "        \n",
    "        # Compact the graph (Step 2)\n",
    "        pos_pair_graph, neg_pair_graph = dgl.compact_graphs([pos_pair_graph, neg_pair_graph])\n",
    "        \n",
    "        # Construct blocks (Step 3)\n",
    "        # Note that pos_pair_graph and neg_pair_graph have the same set of users and items, so we only need\n",
    "        # to check one of them to get the seed nodes.\n",
    "        seeds = {'user': pos_pair_graph.nodes['user'].data[dgl.NID],\n",
    "                 'item': pos_pair_graph.nodes['item'].data[dgl.NID]}\n",
    "        # Note that here we would also remove edges connecting between users and both the corresponding positive\n",
    "        # and negative items appearing in the minibatch.\n",
    "        blocks = self.construct_blocks(seeds, (torch.cat([users, users]), torch.cat([items, neg_items])))\n",
    "        \n",
    "        # Copy node features from original graph to the sampled block.\n",
    "        # Note that for our model we only need to copy the features to the source side of the first block.\n",
    "        for feature_name in self.graph.nodes['user'].data.keys():\n",
    "            blocks[0].srcnodes['user'].data[feature_name] = \\\n",
    "                self.graph.nodes['user'].data[feature_name][blocks[0].srcnodes['user'].data[dgl.NID]]\n",
    "        for feature_name in self.graph.nodes['item'].data.keys():\n",
    "            blocks[0].srcnodes['item'].data[feature_name] = \\\n",
    "                self.graph.nodes['item'].data[feature_name][blocks[0].srcnodes['item'].data[dgl.NID]]\n",
    "            \n",
    "        return pos_pair_graph, neg_pair_graph, blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dgl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91f4586c667beba9fc73d5e38cfe2361778c9000e218f655761c33977cb8e239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
